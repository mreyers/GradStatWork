---
title: "Homework 1"
author: "Matthew Reyers and Dani Chu"
date: "January 9, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

1. Arithmetic exception in a sum.
(a) Write a simple function mysum() that uses a for loop to add successive elements of a vector.
```{r}
mysum <- function(vec){
  curr.sum <- 0
  for( i in 1:length(vec)){
    curr.sum <- curr.sum + vec[i]
  }
  return(curr.sum)
}
```

(b) Create a vector vec having a single element which diﬀers by several orders of magnitude from the remaining elements. Make one element stand out and keep the other elements to be the same. Construct your vector so that mysum(vec) is not the same as mysum(rev(vec))=sum(vec). 
- Unsure if one direction should break the function or if I should make use of cancellation errors in f.p.
```{r}
vec <- c(1:10, factorial(170)) 
rev(vec)
mysum(vec)
mysum(rev(vec))
sum(vec)
```


(c) Suggest a ﬁx to mysum() so that mysum(vec)=sum(vec).



Underﬂow
(a) Set the random seed to 1 and simulate 600 standard normal variates.
```{r}
set.seed(1)
samp <- rnorm(n = 600)
```

(b) Calculate the likelihood at µ = 0 and σ = 1 based on the ﬁrst n observations, for n = 1,...,600. At what value of n does underﬂow occur?
```{r}
likeFun <- function(variates){
  likelihood <- prod(dnorm(variates))
  return(likelihood)
}

logLikeFun <- function(variates){
  likelihood <- sum(log(dnorm(variates)))
  return(likelihood)
}

res <- rep(0, n = 600)
res2<- rep(0, n = 600)
for(j in 1:600){
  res[j] <- likeFun(samp[1:j])
  res2[j]<- logLikeFun(samp[1:j])
}
```
The value underflowed between entry 521 and 522 as it went from having value `r res[521]` to `r res[522]`.  

(c) Suggest an alternate approach to ﬁnd the maximum likelihood estimate of µ and σ that avoids underﬂow.

The most logical approach to calculating maximum likelihood without underflow would be to utilize a transformation. A common transformation to apply is the log transform as it maintains the order of terms and we are dealing with strictly positive values.Doing this transformation and summing each term, rather than multiplying the non-transformed data, will result in fewer instances of underflow. 


2.a) Write an inverse-method approach to sampling from the double exponential distribution.
```{r}
doubleExp <- function(u, alpha){
  if( u >= 0.5 ){
    # Use the CDF for the positive side of interval
    x <- -log(2 - 2*u) / alpha 
  }
  else{
    # Use the CDF for the negative side of interval
    x <- log(2*u) / alpha
  }
  return(x)
}


# Test this function
myVals <- runif(1000) %>% as.matrix(ncol = 1)
dist <- apply(myVals, MARGIN = 1, FUN = doubleExp, alpha = 2)

# That looks about right
```


2.b) Generate a random variable with a given piecewise distribution using the inverse method.
```{r}
pmfGenerator <- function(u){
  # x = 1 has density 0.3
  if( u <= 0.3){
    x = 1
    return(x)
  }
  
  # x = 2 has density 0.2
  if( u <= 0.5){
    x = 2
    return(x)
  }
  
  # x = 4 has density 0.2
  if( u <= 0.7){
    x = 4
    return(x)
  }
  
  # x = 6 has density 0.3
  if( u <= 1){
    x = 6
    return(x)
  }

}

pmf <- apply(myVals, MARGIN = 1, FUN = pmfGenerator)
hist(pmf)
```

c) Use the rexp() function to generate 1000 deviates. Use these to generate two other distributions, namely the chi square on 4 degree of freedom and the Beta(2,3)
```{r}
expDeviates <- rexp(1000) %>% as.matrix(ncol = 1)# Mean of rate  = 1 is 1

# Using the inverse method, we can find the x values from our generated exponentials and plug
# into the pdfs of interest

# Chi-square
chiSqDeviates <- function(v){
  # v is a rexp input
  x <- 4 * v ^ .5 # By derivation of chi sq wrt exponential
  return(x)
}

chiSqVals <- apply(expDeviates, MARGIN = 1, chiSqDeviates) 
hist(chiSqVals) # Not a bad generation

# Almost have the right idea for the second part, keep mixing up the exponential and uniform random generates
```

d) Use the rgamma() and rpois() functions to generate 1000 negative binomial random deviates with parameters r = 2 and p = 0.4 via a gamma mixture of Poisson random variables. Plot a histogram, discuss variance vs. mean in sample, and a few other things.


4. Accept-reject method
a) Given the following scheme for a discrete RV X on the set of positive integers, generate U~U(0,1) and describe X as a function of U. What is the expression for the pmf of f(x)?

The first interval in is bound on [0, 1/2), the next [1/2, 1/4), and so on in increasing powers of (1/2). This means the density associated with each point is the difference between a power of 1/2 and the next power of the same base. So X = 1 has density 1/2, X = 2 has density 1/4, so on and so forth. This means f(x) = (1/2)^x, X belongs to positive integers.

b) Derive the average probability of accepting proposals where U ~ U(0,1) is the uniform deviate used to decide whether to accept the random proposal X  from the distribution g and M is the bounding constant in the accept-reject algorithm.

The average probability of accepting will be 1 / M. Derivation for this can be found attached to this submission as we have written it out by hand.

c) Write a function to draw standard normal deviates X using accept-reject, with proposal distribution for X being g(x|a) for a double exponential distribution on parameter a. 
```{r}
library(smoothmest) # For easy double exponential / laplace dist

acc_rej_standard_normal <- function(n, a, M){
  # Given a number of replicates and a parameter 'a' for the laplace distribution, sample from the standard normal distribution
  laplace_vals <- rdoublex(n, mu = 0, lambda = a)
  uni_vals <- runif(n)
  
  # Get the densities of the normal values and the proposal density
  norm_dens <- dnorm(laplace_vals)
  laplace_dens <- ddoublex(laplace_vals, lambda = a)
  
  # Calculate ratio of densities
  ratio_dens <- norm_dens / (M * laplace_dens)
  
  # Accept or reject?
  results <- data.frame(uni = uni_vals, variates = laplace_vals, ratio = ratio_dens) %>% filter(uni <= ratio)
  
  return(results)
}
```

d) Test the function defined in c) for efficacy on a = 1 with 1000 replicates. Compare the q-q plot with that of the standard normal.
```{r}
the_New_Normal <- acc_rej_standard_normal(1000, 1, 2)
the_New_Normal %>% select(variates) %>% ggplot(aes(sample = variates)) + geom_qq_line() + stat_qq() + ggtitle("Comparison of Accept-Reject Quantiles with Standard Normal")
```
Not quite done with qqnorm but same result. The quantile-quantile plot looks right along what is expected of the standard normal distribution.


e) 

f) Time the function with 10000 standard normal deviates under different values of a. Report the timings and address whether the result agres with previous work.
```{r}
a <- c(0.1, 0.5, 1.0, 1.5, 2.0)
n <- 10000

# Time it
for(i in 1:length(a)){
  print(system.time(acc_rej_standard_normal(n, a[i], 2))) # Change M to the optimal value when found
}
```
The smaller values of parameter a tend to be better but the difference is nearly negligible, especially at a small number of iterations (n = 10000). 
