---
title: "Stat 851 Ass 5"
author: "Matthew Reyers"
date: "March 23, 2019"
output: html_document
---


Surely this is the assignment where it all clicks and everything starts to go better. Surely.

1. There are boats. These boats were made of different types, at different times, and operated over different periods. We are interested in the number of accidents occurring for boats of the given parameters as this will inform us on the risk of damage associated.

a) Write down a reasonable preliminary Poisson GLM for the data.

```{r}
library(tidyverse)
ships <- read_table2("ship.txt") %>% mutate(Construction = as.character(Construction), Operation = as.character(Operation))

```

Answer: Let $Y_{ijkl} \sim Poisson(t_{l} \theta)$ where $Y_{ijkl}$ is the number of accidents incurred for ship $l$ of type $i$ built in the years $j$ and operated in the period $k$ with respect to its service time $t_{l}$.

I will utilize the log link for the Poisson. This means that there is an offset term to account for as we are modeling the rate here but need to model the mean. As such the systematic component looks as follows.

$log(\mu_{ijkl}) = \mu + log(t_{l}) + \alpha_i + \gamma_j + \psi_k$

$\alpha_0 = 0$
$\gamma_0 = 0$
$\psi_0 = 0$

The number of accidents are assumed to be independent between ships.


b) Provide an interpretation of the estimated effect of period of operation based on the model in b).
```{r}
pois_glm <- glm(Accidents~ ShipType + Construction + Operation, data = ships, family = poisson, offset = log(ServiceTime))
pois_sum <- summary(pois_glm)

```

The model returns an effect for Operation on the log scale due to the link function used. To more clearly interpret, I will consider the backtransformed version $e^{\psi_k}$. Note that $\psi_0=0$ which corresponds to the operation period of 1960. Therefore the interpretation is that operating the ship in 1975 has a multiplicative effect on the mean number of accidents inccured of $e^{\psi_1}$ = `r exp(pois_sum$coefficients[5,1])`.

# Probably need to mention more about the baseline value fo 1960 #

c) Which ships have the lowest and highest estimated accident rates?

Answer: Estimation would be based on the output of the model above. Since we need a service time, I will feed them all the same service time such that the intercept is identical. 
```{r}
ship_types <- unique(ships$ShipType)
ship_builds <- unique(ships$Construction)
ship_ops <- unique(ships$Operation)

my_grid <- expand.grid(ship_types, ship_builds, ship_ops)
names(my_grid) <- c("ShipType", "Construction", "Operation")
my_grid$ServiceTime <- 1000

output <- predict.glm(pois_glm, newdata = my_grid)
my_grid$pred <- output

# Pretty plots because why not
my_grid %>% ggplot(aes(x = Construction, y = pred, col = ShipType, group = ShipType)) + geom_point() + geom_line() +
  ggtitle("Comparison of Accident predictions for given specifications") + xlab("Year of Construction") + ylab("Predicted Accident Rates") +
  theme_bw() +
  facet_wrap(~ Operation)
```

# Check if I need to model rate or mean here, specifically for conclusion
The plot above indicates that the ships with the highest rate of accidents tended to be ships of type A, specifically those built in 1970 and operated from 1975-1979. The lowest expected accident rate existed for the ships of type C built in 1960 and operated from 1960-1974.




2. Working with the data for the interferon relapse study, 

a) Fit a Poisson GLM with log link. What is the assumed variance function and dispersion parameter? Compute the p-value for treatment effect.

```{r}
relapse <- read_table2("relapse.txt")

basic_glm <- glm(Relapses ~ Treatment, data = relapse, family = poisson(link = "log"))
res <- anova(basic_glm, test = "Chisq")
chi_val <- res$`Pr(>Chi)`[2]
```

Evaluating the Poisson distribution such that I can identify the dispresion parameter requires the distribution to be written in the form of $f(x) = exp(\frac{x\theta - B(\theta)}{\phi} + C(y, \phi))$

This can be simply done with the Poisson distribution as it takes the following form:
$f(x) = exp(xln(\lambda) - \lambda - ln(x!))$

Letting $\theta = ln(\lambda)$, I can rewrite the distribution as $f(x) = exp(x\theta - e^{\theta} - ln(x!))$

Further, $f(x) = exp(\frac{x\theta - e^{\theta}}{1} - ln(x!))$

This means that $B(\theta) = exp(\theta)$ and $\phi = 1$. Deriving the variance function is then done through $Var(x) = \phi * B^{''}(\theta)$

$Var(x) = \lambda$, $\phi = 1$, and so we expect $B^{''}(\theta) = \lambda$. This happens to be the case as the derivative of $B(\theta)$ is $B(theta)$, which evaluates to $\lambda$.

The assumed variance function is then the mean $\lambda$ and the dispersion parameter is assumed to be 1. 

I would then use the chi-sq test for significance as the dispersion parameter is assumed to be 1. If it were not known then the F-test would make more sense. As is, the resulting p-value is `r chi_val`, allowing the conclusion that there is an effect of treatment on the number of relapses a patient would incur over a two year period.

# Review if I can make that statement with respect to the variable and not the link

b) Compute the average and sample variances of the number of relapses per treatment group. Consistent with mean-variance relationship assumed in a)?

```{r}
relapse %>% group_by(Treatment) %>% summarize(avg = mean(Relapses),
                                              samp_var = var(Relapses)) %>% ggplot(aes(x = avg, y = samp_var)) + geom_point() +
  geom_abline(slope = 1, intercept = 0) + ggtitle("Mean Variance Assumption Check") + xlab("Mean") + ylab("Variance")
```

The expectation is that the mean and variance are roughly equivalent to each other and that the variance grows proportional to the mean. The above plot suggests that the variance does grow with mean and is only a shift away from equivalence. I would be fine proceeding with the assumptions from a).

c) Do the same work for the quasilikelihood as done in a).

```{r}
quasi_glm <- glm(Relapses ~ Treatment, data = relapse, family = quasipoisson(link = "log"))
quasi_res <- anova(quasi_glm, test = "F")
quasi_p <- quasi_res$`Pr(>F)`[2]
```

The p-value associated with the test in the quasi-likelihood setting is `r quasi_p` which leads to the same conclusion as the previous testing environment though with a more conservative p-value. This is due to the F-test being used in place of the chi-sq test.


d) Give the dispersion parameter estimate in c). Is the estimate consistent with conclusion in b)?

```{r}
quasi_sum <- summary(quasi_glm)

```

The dispersion parameter is estimated to be `r quasi_sum$dispersion`. The value is different from 1 in its estimation but it is not so different that the original approach is unreasonable. More data would be able to draw a definite conclusion along this line.

e) Which p-value would I report as a consultant?

Answer: I would logically report the p-value from c). They lead to the same conclusions in this case but c) is more conservative as it makes fewer assumptions about known values. It always feels safer to stay on the side of caution in the case where Type 1 errors are assumed to be worse than Type 2 errors.


3. Income and political party data. Note that income is meant to be listed as catagorical.

a) Produce an interaction plot to show the association between Party and Income. What does your plot suggest about this association?
```{r}
income <- read_table2("party.txt") %>% mutate(Income2 = as.character(Income)) %>% mutate(Income2 = fct_reorder(Income2, Income))

income %>% ggplot(aes(x = Income2, y = Count, group = Party, col = Party)) + geom_point() + geom_line() +
  ggtitle("Interaction plot for Income and Party levels") + xlab("Income level") + ylab("Count") + theme_bw()
```

First of all, the interaction plot suggests that there is an interaction as there are multiple intersections in this plot. Further, there seems to be a relationship between higher income and conservative identification as well as lower income being more strongly associated with NDP membership.


b) Write down a multinomial logit model for these data that will allow me to answer the question of interest. Include necessary parameter constraints. 

# Have not yet covered